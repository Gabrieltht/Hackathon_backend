{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-10T04:33:14.969963Z",
     "start_time": "2023-05-10T04:33:02.184981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 00:33:06.508494: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras.layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import load_img\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import img_to_array\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "base_dir = r\"/Users/xuxuruoning/PycharmProjects/pythonProject2/data/train\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T04:33:29.458213Z",
     "start_time": "2023-05-10T04:33:29.443256Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22664 images belonging to 5 classes.\n",
      "Found 2516 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "#pre=processing\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "train_datagen = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_datagen = test_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='validation'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T04:33:31.159079Z",
     "start_time": "2023-05-10T04:33:30.235150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "cnn = tf.keras.Sequential()\n",
    "cnn.add(keras.layers.Conv2D(filters=64, padding='same', strides=2, kernel_size=3, activation='relu', input_shape=(224,224,3)))\n",
    "cnn.add(keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(keras.layers.Flatten())\n",
    "cnn.add(keras.layers.Dense(5, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T04:33:31.365596Z",
     "start_time": "2023-05-10T04:33:31.175942Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T04:33:32.783045Z",
     "start_time": "2023-05-10T04:33:32.760800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 00:33:36.243513: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/355 [==============================] - ETA: 0s - loss: 1.6981 - accuracy: 0.3172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 00:41:36.033367: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/355 [==============================] - 489s 1s/step - loss: 1.6981 - accuracy: 0.3172 - val_loss: 1.4703 - val_accuracy: 0.3871\n",
      "Epoch 2/10\n",
      "355/355 [==============================] - 471s 1s/step - loss: 1.4823 - accuracy: 0.3733 - val_loss: 1.4627 - val_accuracy: 0.3979\n",
      "Epoch 3/10\n",
      "355/355 [==============================] - 891s 3s/step - loss: 1.4543 - accuracy: 0.3916 - val_loss: 1.4178 - val_accuracy: 0.4237\n",
      "Epoch 4/10\n",
      "355/355 [==============================] - 448s 1s/step - loss: 1.4428 - accuracy: 0.3956 - val_loss: 1.4130 - val_accuracy: 0.4277\n",
      "Epoch 5/10\n",
      "355/355 [==============================] - 487s 1s/step - loss: 1.4241 - accuracy: 0.4085 - val_loss: 1.4068 - val_accuracy: 0.4261\n",
      "Epoch 6/10\n",
      "355/355 [==============================] - 618s 2s/step - loss: 1.4141 - accuracy: 0.4130 - val_loss: 1.4053 - val_accuracy: 0.4308\n",
      "Epoch 7/10\n",
      "355/355 [==============================] - 1817s 5s/step - loss: 1.3996 - accuracy: 0.4189 - val_loss: 1.4012 - val_accuracy: 0.4340\n",
      "Epoch 8/10\n",
      "355/355 [==============================] - 441s 1s/step - loss: 1.3927 - accuracy: 0.4282 - val_loss: 1.3980 - val_accuracy: 0.4324\n",
      "Epoch 9/10\n",
      "355/355 [==============================] - 1858s 5s/step - loss: 1.3837 - accuracy: 0.4348 - val_loss: 1.3979 - val_accuracy: 0.4269\n",
      "Epoch 10/10\n",
      "355/355 [==============================] - 843s 2s/step - loss: 1.3819 - accuracy: 0.4354 - val_loss: 1.3636 - val_accuracy: 0.4404\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x162d08c90>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cnn.fit(train_datagen, epochs=10, validation_data=test_datagen)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T06:53:00.822087Z",
     "start_time": "2023-05-10T04:33:33.448245Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "\n",
    "def predict_which(rslt):\n",
    "    l = [\"angry\", \"fear\", \"happy\", \"neutral\", \"sad\"]\n",
    "    l1 = []\n",
    "    for i in range(4):\n",
    "        l1.append(rslt[0][i])\n",
    "    m = l1.index(max(l1))\n",
    "    return l[m]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T06:58:29.976629Z",
     "start_time": "2023-05-10T06:58:29.969409Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "fear\n"
     ]
    }
   ],
   "source": [
    "img_pred = load_img(\"/Users/xuxuruoning/PycharmProjects/pythonProject2/data/validation/angry/377.jpg\",\n",
    "target_size = (224,224))\n",
    "i = img_to_array(img_pred)\n",
    "i = np.expand_dims(i, axis=0)\n",
    "rslt = cnn.predict(i)\n",
    "print(predict_which(rslt))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T07:05:20.208845Z",
     "start_time": "2023-05-10T07:05:20.078338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
